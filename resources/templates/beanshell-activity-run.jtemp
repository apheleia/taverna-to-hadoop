<%@ requires imports = "org.apache.hadoop.fs.Path,org.apache.hadoop.io.NullWritable,org.apache.hadoop.io.Text,org.apache.hadoop.mapreduce.lib.input.FileInputFormat,org.apache.hadoop.mapreduce.lib.output.FileOutputFormat,org.apache.hadoop.mapreduce.lib.input.TextInputFormat,org.apache.hadoop.mapreduce.lib.output.TextOutputFormat,org.apache.hadoop.mapreduce.Job,org.apache.hadoop.conf.Configuration" %>
		Configuration conf<%= configName %> = getConf();
		Job jobConf<%= configName %> = new Job(conf<%= configName %>, "<%= configName %>");
		
		jobConf<%= configName %>.setInputFormatClass(<%= inputFormat %>.class);
		jobConf<%= configName %>.setOutputFormatClass(<%= outputFormat %>.class);
		jobConf<%= configName %>.setOutputKeyClass(Text.class);
		jobConf<%= configName %>.setOutputValueClass(NullWritable.class);
		
		jobConf<%= configName %>.setMapperClass(<%= configName %>MultipleInputsMap.class);
		jobConf<%= configName %>.setReducerClass(<%= configName %>BeanshellReduce.class);
		
		jobConf<%= configName %>.setJarByClass(<%= hadoopClassName %>.class);
		
		FileInputFormat.setInputPaths(jobConf<%= configName %>, <%= inputPath %>);
		FileOutputFormat.setOutputPath(jobConf<%= configName %>, new Path(<%= outputPath %>));
		
		<%= multipleOutputsRun %>
		
		jobConf<%= configName %>.waitForCompletion(true);